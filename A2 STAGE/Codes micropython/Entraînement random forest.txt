import numpy as np
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import GridSearchCV, train_test_split
from sklearn.metrics import accuracy_score



# Initialisation des listes de caractéristiques
# Rentrer les résultats à partir du code "code final" ou "code final commente"
deltaf = []
integralef = []
derivee_maxf = []
sommef = []
y = []



# Concaténation des caractéristiques dans une seule matrice
X = np.column_stack((deltaf, integralef, derivee_maxf, sommef))

# Division des données en ensemble d'entraînement et de test
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)

# Définition des paramètres pour la recherche sur grille
param_grid = {
    'n_estimators': [50, 100, 200],
    'nb_arbres': [None, 10, 20, 30],
    'nb_minimum noeuds': [2, 5, 10],
    'nb_minimum_feuilles': [1, 2, 4]
}

# Création du modèle de Random Forest
model = RandomForestClassifier(random_state=42)

# Création de l'objet GridSearchCV
grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, n_jobs=-1, verbose=2)

# Exécution de la recherche sur grille
grid_search.fit(X_train, y_train)

# Affichage des meilleurs paramètres
print(f"Résultats de l'entraînement : {grid_search.best_params_}")

# Utilisation du meilleur modèle pour prédire sur l'ensemble de test
meilleur_modele = grid_search.best_estimator_
y_pred = best_model.predict(X_test)

# Évaluation du modèle
precision = accuracy_score(y_test, y_pred)
print(Precision du modèle: {precision * 100:.2f}%')

# Affichage des prédictions
print("Y test: ", y_test)
print("Y prédit ", y_pred)
